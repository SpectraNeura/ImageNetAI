import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.models as models
import torchvision.transforms as transforms
from torch.utils.data import DataLoader, Dataset
from PIL import Image
import os
import numpy as np
import cv2

# GPU ì‚¬ìš© ì—¬ë¶€ í™•ì¸
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")


# ------------------------------
# 1. ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬
# ------------------------------
class ColorizationDataset(Dataset):
    def __init__(self, input_dir, gt_dir, transform=None):
        self.input_dir = input_dir
        self.gt_dir = gt_dir
        self.transform = transform
        self.image_filenames = [f for f in os.listdir(input_dir) if os.path.isfile(os.path.join(input_dir, f))]

        # ğŸ”¥ ìœ íš¨í•œ íŒŒì¼ë§Œ ìœ ì§€
        self.image_filenames = [f for f in self.image_filenames if os.path.exists(os.path.join(self.gt_dir, f))]

    def __len__(self):
        return len(self.image_filenames)

    def __getitem__(self, idx):
        filename = self.image_filenames[idx]
        input_path = os.path.join(self.input_dir, filename)
        gt_path = os.path.join(self.gt_dir, filename)

        gray_img = Image.open(input_path).convert("L").resize((256, 256))
        color_img = Image.open(gt_path).convert("RGB").resize((256, 256))

        if self.transform:
            gray_img = self.transform(gray_img)
            color_img = self.transform(color_img)

        return gray_img, color_img


# ë°ì´í„° ë³€í™˜ ì •ì˜
transform = transforms.Compose([
    transforms.ToTensor()
])

# ë°ì´í„°ì…‹ ë¡œë“œ
train_dataset = ColorizationDataset("../picture/train_input/", "../picture/train_gt/", transform=transform)
if len(train_dataset) == 0:
    raise ValueError("Error: No valid images found in dataset. Check file paths.")
train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)


# ------------------------------
# 2. VGG19 Feature Extractor ì •ì˜
# ------------------------------
class VGG19FeatureExtractor(nn.Module):
    def __init__(self):
        super(VGG19FeatureExtractor, self).__init__()
        vgg19 = models.vgg19(pretrained=True)
        self.features = nn.Sequential(*list(vgg19.features.children())[:23])  # conv4_4ê¹Œì§€ ì‚¬ìš©
        for param in self.features.parameters():
            param.requires_grad = False  # ê°€ì¤‘ì¹˜ ê³ ì •

    def forward(self, x):
        return self.features(x)


# ------------------------------
# 3.  ì»¬ëŸ¬í™” ëª¨ë¸ ì •ì˜ (ì˜¤ë¥˜ ìˆ˜ì • ì™„ë£Œ)
# ------------------------------
class ColorizationModel(nn.Module):
    def __init__(self):
        super(ColorizationModel, self).__init__()
        self.vgg19 = VGG19FeatureExtractor()

        #  1ì±„ë„ â†’ 3ì±„ë„ ë³€í™˜
        self.input_conv = nn.Conv2d(1, 3, kernel_size=3, padding=1)

        #  Decoder ë„¤íŠ¸ì›Œí¬ ( ì˜¤ë¥˜ ìˆ˜ì •: ì—…ìƒ˜í”Œë§ í›„ Conv2d í¬ê¸° ì¡°ì •)
        self.decoder = nn.Sequential(
            nn.Upsample(scale_factor=2, mode="bilinear", align_corners=False),
            nn.Conv2d(512, 256, kernel_size=3, padding=1),
            nn.ReLU(),

            nn.Upsample(scale_factor=2, mode="bilinear", align_corners=False),
            nn.Conv2d(256, 128, kernel_size=3, padding=1),
            nn.ReLU(),

            nn.Upsample(scale_factor=2, mode="bilinear", align_corners=False),
            nn.Conv2d(128, 64, kernel_size=3, padding=1),
            nn.ReLU(),

            nn.Conv2d(64, 3, kernel_size=3, padding=1),
            nn.Sigmoid()
        )

    def forward(self, x):
        x = self.input_conv(x)  #  í‘ë°±(1ì±„ë„) â†’ RGB(3ì±„ë„) ë³€í™˜
        features = self.vgg19(x)  # VGG19 íŠ¹ì§• ì¶”ì¶œ
        output = self.decoder(features)  #  ì»¬ëŸ¬í™”
        return output


# ------------------------------
# 4. ëª¨ë¸ í•™ìŠµ ì„¤ì •
# ------------------------------
model = ColorizationModel().to(device)
criterion = nn.L1Loss()  # ğŸ”¥ L1 ì†ì‹¤ í•¨ìˆ˜ (MAE)
optimizer = optim.Adam(model.parameters(), lr=0.001)

# ------------------------------
# 5. ëª¨ë¸ í•™ìŠµ ë£¨í”„
# ------------------------------
num_epochs = 10
for epoch in range(num_epochs):
    model.train()
    total_loss = 0

    for data in train_loader:
        gray_imgs, color_imgs = data
        gray_imgs, color_imgs = gray_imgs.to(device), color_imgs.to(device)

        optimizer.zero_grad()
        outputs = model(gray_imgs)

        loss = criterion(outputs, color_imgs)  # L1 Loss
        loss.backward()
        optimizer.step()

        total_loss += loss.item()

    print(f"Epoch [{epoch + 1}/{num_epochs}], Loss: {total_loss / len(train_loader):.4f}")


# ------------------------------
# 6. í…ŒìŠ¤íŠ¸ ë° ê²°ê³¼ ì €ì¥
# ------------------------------
def colorize_image(model, image_path):
    model.eval()

    if not os.path.exists(image_path):
        print(f"Error: {image_path} not found.")
        return None

    gray_img = Image.open(image_path).convert("L").resize((256, 256))
    transform = transforms.ToTensor()
    gray_tensor = transform(gray_img).unsqueeze(0).to(device)

    with torch.no_grad():
        output = model(gray_tensor)

    output = output.squeeze(0).cpu().numpy().transpose(1, 2, 0)
    output = (output * 255).astype(np.uint8)

    return output


#  í…ŒìŠ¤íŠ¸ ì‹¤í–‰
test_image_path = "../picture/test_input/TEST_001.png"
colorized_output = colorize_image(model, test_image_path)
if colorized_output is not None:
    cv2.imwrite("../picture/colorized_output.png", colorized_output)